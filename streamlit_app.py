import streamlit as st
import pandas as pd
import re
import time
from io import StringIO, BytesIO
from openai import OpenAI
from datetime import datetime
import json
import zipfile

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ğŸ¥ MedLLM Benchmark",
    page_icon="ğŸ¥",
    layout="wide",
)

# --- CSS ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2.5rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(102, 126, 234, 0.3);
    }
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin: 0;
        text-shadow: 0 2px 4px rgba(0,0,0,0.2);
    }
    
    /* ì œì¶œ ì„¹ì…˜ ìŠ¤íƒ€ì¼ë§ */
    .submit-section {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 2rem;
        border-radius: 15px;
        border: 1px solid #dee2e6;
        margin-bottom: 2rem;
        box-shadow: 0 4px 16px rgba(0,0,0,0.1);
    }
    
    .submit-header {
        color: #2c3e50;
        font-size: 1.5rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    .submit-info {
        color: #6c757d;
        margin-bottom: 1.5rem;
        font-size: 1rem;
    }
    
    /* ì…ë ¥ í•„ë“œì™€ ë²„íŠ¼ ì •ë ¬ */
    .input-container {
        display: flex;
        gap: 1rem;
        align-items: end;
    }
    
    .input-field {
        flex: 1;
    }
    
    .submit-button {
        flex-shrink: 0;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stButton>button {
        background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        font-size: 1rem;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(40, 167, 69, 0.3);
        height: 56px;
    }
    
    .stButton>button:hover {
        background: linear-gradient(135deg, #218838 0%, #1ba085 100%);
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(40, 167, 69, 0.4);
    }
    
    /* ê´€ë¦¬ì ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .admin-button button {
        background: linear-gradient(135deg, #6c757d 0%, #495057 100%);
        border-radius: 50%;
        width: 50px;
        height: 50px;
        font-size: 1.2rem;
    }
    
    /* ë²¤ì¹˜ë§ˆí¬ ì¹´ë“œ ê°œì„  */
    .benchmark-card {
        border: none;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        color: #333;
        box-shadow: 0 4px 20px rgba(0,0,0,0.08);
        transition: all 0.3s ease;
    }
    
    .benchmark-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 30px rgba(0,0,0,0.12);
    }
    
    .benchmark-card h4 {
        color: #2c3e50;
        margin-bottom: 0.8rem;
        font-weight: 600;
        font-size: 1.1rem;
    }
    
    .benchmark-card p {
        color: #6c757d;
        margin: 0.4rem 0;
        font-size: 0.9rem;
    }
    
    .benchmark-rank {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 50%;
        width: 60px;
        height: 60px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-weight: 700;
        font-size: 1.5rem;
        box-shadow: 0 4px 16px rgba(102, 126, 234, 0.3);
    }
    
    .accuracy-score {
        text-align: center;
        padding: 1rem;
        background: rgba(255,255,255,0.8);
        border-radius: 12px;
        border: 2px solid #e9ecef;
    }
    
    .accuracy-high { 
        color: #28a745; 
        font-weight: 700;
        font-size: 2rem;
    }
    .accuracy-medium { 
        color: #ffc107; 
        font-weight: 700;
        font-size: 2rem;
    }
    .accuracy-low { 
        color: #dc3545; 
        font-weight: 700;
        font-size: 2rem;
    }
    
    /* ëŒ€ê¸°ì—´ ì •ë³´ ìŠ¤íƒ€ì¼ */
    .queue-info {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #2196f3;
        margin: 1rem 0;
    }
    
    /* ì„¹ì…˜ í—¤ë” ìŠ¤íƒ€ì¼ */
    .section-header {
        color: #2c3e50;
        font-weight: 600;
        margin: 2rem 0 1rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 3px solid #667eea;
    }
</style>
""", unsafe_allow_html=True)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'benchmark_results' not in st.session_state:
    # ìƒ˜í”Œ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìƒì„± (Qwen3 30B ì´í•˜ ëª¨ë¸ë“¤)
    st.session_state.benchmark_results = [
        {
            'id': 1,
            'model_name': 'Qwen/Qwen3-14B-Instruct',
            'accuracy': 86.7,
            'total_questions': 240,
            'correct_answers': 208,
            'evaluation_date': '2025-01-25 14:30:22',
            'dataset_name': 'Medical QA Dataset v1.2',
            'api_errors': 1
        },
        {
            'id': 2,
            'model_name': 'Qwen/Qwen3-7B-Instruct',
            'accuracy': 82.1,
            'total_questions': 240,
            'correct_answers': 197,
            'evaluation_date': '2025-01-24 16:45:11',
            'dataset_name': 'Medical QA Dataset v1.2',
            'api_errors': 2
        },
        {
            'id': 3,
            'model_name': 'Qwen/Qwen3-3B-Instruct',
            'accuracy': 77.5,
            'total_questions': 240,
            'correct_answers': 186,
            'evaluation_date': '2025-01-23 09:15:33',
            'dataset_name': 'Medical QA Dataset v1.2',
            'api_errors': 1
        },
        {
            'id': 4,
            'model_name': 'Qwen/Qwen3-1.5B-Instruct',
            'accuracy': 71.3,
            'total_questions': 240,
            'correct_answers': 171,
            'evaluation_date': '2025-01-22 11:20:45',
            'dataset_name': 'Medical QA Dataset v1.1',
            'api_errors': 4
        },
        {
            'id': 5,
            'model_name': 'Qwen/Qwen3-0.5B-Instruct',
            'accuracy': 63.8,
            'total_questions': 240,
            'correct_answers': 153,
            'evaluation_date': '2025-01-21 13:50:17',
            'dataset_name': 'Medical QA Dataset v1.2',
            'api_errors': 7
        }
    ]

if 'admin_mode' not in st.session_state:
    st.session_state.admin_mode = False

if 'admin_authenticated' not in st.session_state:
    st.session_state.admin_authenticated = False

if 'test_dataset' not in st.session_state:
    # ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ (ì‹¤ì œë¡œëŠ” íŒŒì¼ì—ì„œ ë¡œë“œ)
    st.session_state.test_dataset = None

if 'pending_evaluations' not in st.session_state:
    st.session_state.pending_evaluations = []

# --- HuggingFace OpenAI í˜¸í™˜ API í´ë˜ìŠ¤ ---
class MedicalEvaluator:
    def __init__(self, api_key):
        if not api_key:
            raise ValueError("Hugging Face API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        self.client = OpenAI(
            base_url="https://router.huggingface.co/v1",
            api_key=api_key,
        )

    def query_model(self, model_name, prompt):
        try:
            completion = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10,
                temperature=0.1,
            )
            return completion.choices[0].message.content
        except Exception as e:
            return f"API_ERROR: {str(e)}"

    def evaluate(self, model_name, questions, correct_answers, progress_bar):
        results = []
        total_questions = len(questions)
        api_errors = 0

        for i, (question, correct_answer) in enumerate(zip(questions, correct_answers)):
            prompt = f"""{question}\n\nAnswer with the letter of the correct option (A, B, C, or D).\n\nAnswer:"""
            
            response_text = self.query_model(model_name, prompt)
            
            predicted_answer = "EXTRACT_FAIL"
            error_message = None

            if response_text.startswith("API_ERROR:"):
                error_message = response_text
                predicted_answer = "API_ERROR"
                api_errors += 1
            else:
                match = re.search(r'\b([A-D])\b', response_text.upper())
                if match:
                    predicted_answer = match.group(1)

            is_correct = predicted_answer == correct_answer
            results.append({
                'question': question,
                'correct_answer': correct_answer,
                'predicted_answer': predicted_answer,
                'is_correct': is_correct,
                'raw_response': response_text,
                'error': error_message
            })
            
            progress_bar.progress((i + 1) / total_questions, text=f"Processing {i+1}/{total_questions}")
            time.sleep(0.2)

        return results, api_errors

def get_accuracy_class(accuracy):
    if accuracy >= 85:
        return "accuracy-high"
    elif accuracy >= 70:
        return "accuracy-medium"
    else:
        return "accuracy-low"

def add_benchmark_result(model_name, accuracy, total_questions, correct_answers, dataset_name, api_errors):
    new_id = max([r['id'] for r in st.session_state.benchmark_results]) + 1 if st.session_state.benchmark_results else 1
    new_result = {
        'id': new_id,
        'model_name': model_name,
        'accuracy': accuracy,
        'total_questions': total_questions,
        'correct_answers': correct_answers,
        'evaluation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'dataset_name': dataset_name,
        'api_errors': api_errors
    }
    st.session_state.benchmark_results.append(new_result)

def add_evaluation_request(model_name):
    """í‰ê°€ ìš”ì²­ì„ ëŒ€ê¸°ì—´ì— ì¶”ê°€"""
    if model_name not in [req['model_name'] for req in st.session_state.pending_evaluations]:
        request_id = len(st.session_state.pending_evaluations) + 1
        st.session_state.pending_evaluations.append({
            'id': request_id,
            'model_name': model_name,
            'status': 'pending',
            'submitted_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'evaluated_at': None
        })
        return True
    return False

def load_secure_dataset(uploaded_file, password=None):
    """ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ (ì•”í˜¸í™”ëœ íŒŒì¼ ì§€ì›)"""
    try:
        file_extension = uploaded_file.name.lower().split('.')[-1]
        
        if file_extension == 'csv':
            # CSV íŒŒì¼ ì²˜ë¦¬
            if password:
                # ì•”í˜¸í™”ëœ ZIP ë‚´ì˜ CSV ì²˜ë¦¬
                try:
                    with zipfile.ZipFile(BytesIO(uploaded_file.read()), 'r') as zip_file:
                        zip_file.setpassword(password.encode())
                        # ZIP ë‚´ ì²« ë²ˆì§¸ CSV íŒŒì¼ ì°¾ê¸°
                        csv_files = [f for f in zip_file.namelist() if f.lower().endswith('.csv')]
                        if not csv_files:
                            return False, "ZIP íŒŒì¼ ë‚´ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
                        
                        with zip_file.open(csv_files[0]) as csv_file:
                            df = pd.read_csv(csv_file)
                except Exception as e:
                    return False, f"ì•”í˜¸í™”ëœ ZIP íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"
            else:
                # ì¼ë°˜ CSV íŒŒì¼
                df = pd.read_csv(uploaded_file)
                
        elif file_extension in ['xlsx', 'xls']:
            # ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬
            try:
                if password:
                    return False, "ì•”í˜¸í™”ëœ ì—‘ì…€ íŒŒì¼ì„ ì²˜ë¦¬í•˜ë ¤ë©´ msoffcrypto ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ ZIP ì•”í˜¸í™”ëœ CSV íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
                else:
                    # ì¼ë°˜ ì—‘ì…€ íŒŒì¼
                    df = pd.read_excel(uploaded_file)
                    
            except Exception as e:
                return False, f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"
        else:
            return False, "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV, XLS, XLSX íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤."
        
        # ë°ì´í„° ê²€ì¦
        if 'question' not in df.columns or 'answer' not in df.columns:
            return False, "íŒŒì¼ì— 'question'ê³¼ 'answer' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
        
        # ì„¸ì…˜ì— ì €ì¥
        st.session_state.test_dataset = {
            'questions': df['question'].tolist(),
            'answers': df['answer'].tolist(),
            'total_count': len(df),
            'loaded_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'file_type': file_extension,
            'is_encrypted': password is not None
        }
        
        encryption_info = " (ì•”í˜¸í™”ë¨)" if password else ""
        return True, f"{len(df)}ê°œì˜ ì§ˆë¬¸ì´ í¬í•¨ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.{encryption_info}"
        
    except Exception as e:
        return False, f"ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}"

def delete_benchmark_result(result_id):
    st.session_state.benchmark_results = [r for r in st.session_state.benchmark_results if r['id'] != result_id]

# --- ë©”ì¸ í—¤ë” ---
st.markdown('<div class="main-header"><h1>ğŸ¥ MedLLM Benchmark Results</h1></div>', unsafe_allow_html=True)

# --- ëª¨ë¸ ì œì¶œ ì„¹ì…˜ (ê³µê°œ) ---
st.markdown("""
<div class="submit-section">
    <div class="submit-header">
        ğŸš€ Submit Your Model for Evaluation
    </div>
    <div class="submit-info">
        HuggingFace ëª¨ë¸ ì£¼ì†Œë¥¼ ì œì¶œí•˜ë©´ ìë™ìœ¼ë¡œ í‰ê°€ê°€ ì§„í–‰ë©ë‹ˆë‹¤.
    </div>
</div>
""", unsafe_allow_html=True)

# ì…ë ¥ í•„ë“œì™€ ë²„íŠ¼ì„ ê°™ì€ ë†’ì´ì— ë°°ì¹˜
col_input, col_button = st.columns([4, 1])

with col_input:
    model_submission = st.text_input(
        "HuggingFace Model ID",
        placeholder="ì˜ˆ: Qwen/Qwen3-7B-Instruct",
        help="í‰ê°€í•˜ê³  ì‹¶ì€ HuggingFace ëª¨ë¸ì˜ ì „ì²´ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        label_visibility="collapsed"
    )

with col_button:
    # ë¹ˆ ê³µê°„ìœ¼ë¡œ ë²„íŠ¼ ìœ„ì¹˜ ë§ì¶”ê¸°
    st.markdown("<div style='margin-bottom: 8px;'></div>", unsafe_allow_html=True)
    submit_clicked = st.button("ğŸ“¤ Submit", use_container_width=True, type="primary")

# ì œì¶œ ë¡œì§
if submit_clicked:
    if model_submission.strip():
        success = add_evaluation_request(model_submission.strip())
        if success:
            st.success(f"âœ… {model_submission} í‰ê°€ ìš”ì²­ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.info("ê´€ë¦¬ìê°€ ìŠ¹ì¸í•˜ë©´ ìë™ìœ¼ë¡œ í‰ê°€ê°€ ì§„í–‰ë©ë‹ˆë‹¤.")
            st.rerun()
        else:
            st.warning("âš ï¸ ì´ë¯¸ ì œì¶œëœ ëª¨ë¸ì…ë‹ˆë‹¤.")
    else:
        st.error("âŒ ëª¨ë¸ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# --- ëŒ€ê¸°ì¤‘ì¸ í‰ê°€ í‘œì‹œ ---
if st.session_state.pending_evaluations:
    pending_count = len([req for req in st.session_state.pending_evaluations if req['status'] == 'pending'])
    if pending_count > 0:
        st.markdown(f"""
        <div class="queue-info">
            ğŸ• í˜„ì¬ <strong>{pending_count}ê°œ</strong>ì˜ ëª¨ë¸ì´ í‰ê°€ ëŒ€ê¸°ì¤‘ì…ë‹ˆë‹¤.
        </div>
        """, unsafe_allow_html=True)
        
        with st.expander("ğŸ“‹ ëŒ€ê¸°ì¤‘ì¸ í‰ê°€ ëª©ë¡ ë³´ê¸°"):
            for req in st.session_state.pending_evaluations:
                if req['status'] == 'pending':
                    st.markdown(f"â€¢ **{req['model_name']}** (ì œì¶œ: {req['submitted_at']})")

st.markdown("---")

# --- ê´€ë¦¬ì ëª¨ë“œ í† ê¸€ (ìˆ¨ê¹€) ---
col1, col2, col3 = st.columns([6, 1, 1])
with col3:
    st.markdown('<div class="admin-button">', unsafe_allow_html=True)
    admin_clicked = st.button("ğŸ”§", help="Admin Mode")
    st.markdown('</div>', unsafe_allow_html=True)
    
    if admin_clicked:
        if st.session_state.admin_authenticated:
            # ì´ë¯¸ ì¸ì¦ëœ ê²½ìš° ëª¨ë“œ í† ê¸€
            st.session_state.admin_mode = not st.session_state.admin_mode
            if not st.session_state.admin_mode:
                st.session_state.admin_authenticated = False
        else:
            # ì¸ì¦ì´ í•„ìš”í•œ ê²½ìš°
            st.session_state.admin_mode = True

# --- ê´€ë¦¬ì ì¸ì¦ ì„¹ì…˜ ---
if st.session_state.admin_mode and not st.session_state.admin_authenticated:
    st.markdown("---")
    st.header("ğŸ” Admin Authentication Required")
    
    col_auth1, col_auth2, col_auth3 = st.columns([1, 2, 1])
    with col_auth2:
        password = st.text_input("Enter Admin Password:", type="password", key="admin_password")
        
        col_login, col_cancel = st.columns(2)
        with col_login:
            if st.button("ğŸ”‘ Login", key="admin_login", use_container_width=True):
                if password == "passpass":
                    st.session_state.admin_authenticated = True
                    st.success("âœ… Admin ì¸ì¦ ì„±ê³µ!")
                    st.rerun()
                else:
                    st.error("âŒ ì˜ëª»ëœ ë¹„ë°€ë²ˆí˜¸ì…ë‹ˆë‹¤.")
        
        with col_cancel:
            if st.button("âŒ Cancel", key="admin_cancel", use_container_width=True):
                st.session_state.admin_mode = False
                st.rerun()

# --- ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ í‘œì‹œ ---
st.markdown('<h2 class="section-header">ğŸ“Š Current Benchmark Rankings</h2>', unsafe_allow_html=True)

# ì •í™•ë„ ìˆœìœ¼ë¡œ ì •ë ¬
sorted_results = sorted(st.session_state.benchmark_results, key=lambda x: x['accuracy'], reverse=True)

for i, result in enumerate(sorted_results):
    accuracy_class = get_accuracy_class(result['accuracy'])
    
    col1, col2, col3, col4 = st.columns([1, 4, 2, 1])
    
    with col1:
        st.markdown(f'<div class="benchmark-rank">#{i+1}</div>', unsafe_allow_html=True)
    
    with col2:
        api_error_info = f"<p><strong>âš ï¸ API Errors:</strong> {result['api_errors']}</p>" if result['api_errors'] > 0 else ""
        st.markdown(f"""
        <div class="benchmark-card">
            <h4>ğŸ¤– {result['model_name']}</h4>
            <p><strong>ğŸ“Š Dataset:</strong> {result['dataset_name']}</p>
            <p><strong>ğŸ“… Date:</strong> {result['evaluation_date']}</p>
            {api_error_info}
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="accuracy-score">
            <div class="{accuracy_class}">{result['accuracy']:.1f}%</div>
            <p style="margin: 0.5rem 0 0 0; color: #6c757d; font-size: 0.9rem;">
                {result['correct_answers']} / {result['total_questions']} ì •ë‹µ
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        if st.session_state.admin_mode and st.session_state.admin_authenticated:
            if st.button("ğŸ—‘ï¸", key=f"delete_{result['id']}", help="Delete Result"):
                delete_benchmark_result(result['id'])
                st.rerun()

# --- ê´€ë¦¬ì ëª¨ë“œ: í‰ê°€ ê´€ë¦¬ ---
if st.session_state.admin_mode and st.session_state.admin_authenticated:
    st.markdown("---")
    st.header("ğŸ”§ Admin: Manage Evaluations")

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê´€ë¦¬
    st.subheader("ğŸ“Š Secure Test Dataset")
    if st.session_state.test_dataset:
        encryption_badge = "ğŸ”’ ì•”í˜¸í™”ë¨" if st.session_state.test_dataset.get('is_encrypted', False) else "ğŸ”“ ì¼ë°˜"
        file_type_badge = st.session_state.test_dataset.get('file_type', 'unknown').upper()
        
        st.success(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œë¨: {st.session_state.test_dataset['total_count']}ê°œ ì§ˆë¬¸")
        st.info(f"ğŸ“„ íŒŒì¼ í˜•ì‹: {file_type_badge} | ë³´ì•ˆ: {encryption_badge} | ë¡œë“œ ì‹œê°„: {st.session_state.test_dataset['loaded_at']}")
        
        col_ds1, col_ds2 = st.columns(2)
        with col_ds1:
            if st.button("ğŸ—‘ï¸ Remove Dataset", help="í˜„ì¬ ë¡œë“œëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì œê±°í•©ë‹ˆë‹¤."):
                st.session_state.test_dataset = None
                st.success("ë°ì´í„°ì…‹ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
        
        with col_ds2:
            if st.button("ğŸ”„ Reload Dataset", help="í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤."):
                st.session_state.test_dataset = None
                st.rerun()
    else:
        st.warning("âš ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ì—…ë¡œë“œ ë° ì•”í˜¸ ì…ë ¥
        uploaded_test_file = st.file_uploader(
            "ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì—…ë¡œë“œ",
            type=['csv', 'xlsx', 'xls'],
            help="ì•”í˜¸í™”ëœ íŒŒì¼ë„ ì§€ì›ë©ë‹ˆë‹¤. CSV, Excel íŒŒì¼ ëª¨ë‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            key="secure_dataset"
        )
        
        # ì•”í˜¸ ì…ë ¥ (ì„ íƒì‚¬í•­)
        dataset_password = st.text_input(
            "íŒŒì¼ ì•”í˜¸ (ì„ íƒì‚¬í•­)",
            type="password",
            help="ì•”í˜¸í™”ëœ íŒŒì¼ì˜ ê²½ìš° ì•”í˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì¼ë°˜ íŒŒì¼ì€ ë¹„ì›Œë‘ì„¸ìš”.",
            key="dataset_password"
        )
        
        col_upload1, col_upload2 = st.columns(2)
        
        with col_upload1:
            if st.button("ğŸ“ Load Dataset", help="ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤."):
                if uploaded_test_file:
                    success, message = load_secure_dataset(uploaded_test_file, dataset_password if dataset_password else None)
                    if success:
                        st.success(message)
                        st.rerun()
                    else:
                        st.error(message)
                else:
                    st.error("íŒŒì¼ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        with col_upload2:
            st.info("ğŸ’¡ **ì§€ì› í˜•ì‹:**\n- CSV íŒŒì¼ (ì¼ë°˜/ZIP ì•”í˜¸í™”)\n- Excel íŒŒì¼ (ì¼ë°˜)\n- 'question', 'answer' ì»¬ëŸ¼ í•„ìˆ˜")

    # ëŒ€ê¸°ì¤‘ì¸ í‰ê°€ ê´€ë¦¬
    st.subheader("ğŸ“‹ Pending Evaluation Queue")
    if st.session_state.pending_evaluations:
        pending_requests = [req for req in st.session_state.pending_evaluations if req['status'] == 'pending']
        
        if pending_requests:
            st.info(f"ğŸ• {len(pending_requests)}ê°œì˜ í‰ê°€ ìš”ì²­ì´ ëŒ€ê¸°ì¤‘ì…ë‹ˆë‹¤.")
            
            for req in pending_requests:
                col_req1, col_req2, col_req3 = st.columns([3, 1, 1])
                
                with col_req1:
                    st.text(f"ğŸ“¦ {req['model_name']}")
                    st.caption(f"ì œì¶œ: {req['submitted_at']}")
                
                with col_req2:
                    if st.button("âœ… Approve", key=f"approve_{req['id']}", help="í‰ê°€ ìŠ¹ì¸ ë° ì‹¤í–‰"):
                        if st.session_state.test_dataset:
                            req['status'] = 'approved'
                            st.success("í‰ê°€ê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
                        else:
                            st.error("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
                
                with col_req3:
                    if st.button("âŒ Reject", key=f"reject_{req['id']}", help="í‰ê°€ ìš”ì²­ ê±°ë¶€"):
                        st.session_state.pending_evaluations.remove(req)
                        st.success("í‰ê°€ ìš”ì²­ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                
                st.markdown("---")
        else:
            st.info("ì²˜ë¦¬í•  í‰ê°€ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì œì¶œëœ í‰ê°€ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ìˆ˜ë™ í‰ê°€ ì„¹ì…˜
    st.subheader("ğŸ”§ Manual Evaluation")
    
    with st.sidebar:
        st.header("âš™ï¸ Manual Evaluation Settings")

        st.info("**ê¶Œì¥:** Streamlit Cloudì˜ Secretsì— `HF_TOKEN`ì„ ì„¤ì •í•˜ì„¸ìš”.")
        api_key = st.text_input(
            "Hugging Face Token (hf_...)", 
            type="password", 
            help="Hugging Face API í† í°ì„ ì…ë ¥í•˜ì„¸ìš”.",
            value=st.secrets.get("HF_TOKEN", "")
        )
        
        # ì—¬ëŸ¬ ëª¨ë¸ ì…ë ¥
        model_ids_input = st.text_area(
            "HuggingFace Model IDs (í•œ ì¤„ì— í•˜ë‚˜ì”©)", 
            value="Qwen/Qwen3-14B-Instruct\nQwen/Qwen3-7B-Instruct",
            help="í‰ê°€í•  ëª¨ë¸ë“¤ì„ í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥í•˜ì„¸ìš”.",
            height=150
        )

        dataset_name = st.text_input(
            "Dataset Name",
            value="Medical QA Dataset v1.3",
            help="ë°ì´í„°ì…‹ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”."
        )

    if st.button("ğŸš€ Start Manual Evaluation"):
        if not api_key:
            st.error("âŒ Hugging Face í† í°ì„ ì…ë ¥í•˜ê±°ë‚˜ Secretsì— ì„¤ì •í•˜ì„¸ìš”.")
        elif not model_ids_input.strip():
            st.error("âŒ ëª¨ë¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        elif not st.session_state.test_dataset:
            st.error("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            try:
                # ëª¨ë¸ IDs íŒŒì‹±
                model_ids = [mid.strip() for mid in model_ids_input.strip().split('\n') if mid.strip()]
                
                questions = st.session_state.test_dataset['questions']
                correct_answers = st.session_state.test_dataset['answers']
                
                st.info(f"ğŸ¤– {len(model_ids)}ê°œ ëª¨ë¸ ìˆœì°¨ í‰ê°€ ì‹œì‘...")

                evaluator = MedicalEvaluator(api_key)

                # ê° ëª¨ë¸ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ í‰ê°€
                for model_idx, model_id in enumerate(model_ids):
                    clean_model_id = model_id.strip().strip('"\'')
                    
                    st.subheader(f"Evaluating Model {model_idx + 1}/{len(model_ids)}: {clean_model_id}")
                    
                    progress_bar = st.progress(0, text=f"í‰ê°€ ì‹œì‘: {clean_model_id}")
                    evaluation_results, api_errors = evaluator.evaluate(clean_model_id, questions, correct_answers, progress_bar)
                    progress_bar.empty()

                    results_df = pd.DataFrame(evaluation_results)
                    correct_count = results_df['is_correct'].sum()
                    total_count = len(results_df)
                    accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0

                    # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì— ì¶”ê°€
                    add_benchmark_result(
                        clean_model_id, 
                        accuracy, 
                        total_count, 
                        correct_count, 
                        dataset_name,
                        api_errors
                    )

                    st.success(f"âœ… {clean_model_id}: {accuracy:.2f}% ({correct_count}/{total_count})")
                    
                    if api_errors > 0:
                        st.warning(f"âš ï¸ API ì˜¤ë¥˜ {api_errors}ê°œ ë°œìƒ")

                st.success("ğŸ‰ ëª¨ë“  ëª¨ë¸ í‰ê°€ ì™„ë£Œ! í˜ì´ì§€ê°€ ìƒˆë¡œê³ ì¹¨ë©ë‹ˆë‹¤.")
                time.sleep(2)
                st.rerun()

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

else:
    st.info("ğŸ”§ ê´€ë¦¬ì ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ìš°ì¸¡ ìƒë‹¨ì˜ ì„¤ì • ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
