import streamlit as st
import pandas as pd
import requests
import re
import time
from io import StringIO

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ğŸ¥ MedLLM Simple Evaluator",
    page_icon="ğŸ¥",
    layout="centered",
)

# --- CSS ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# --- HuggingFace API í´ë˜ìŠ¤ ---
class MedicalQA:
    def __init__(self, api_key):
        self.api_key = api_key
        self.api_url = 'https://api-inference.huggingface.co/models/'
        self.headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
        }

    def query_model(self, model_name, prompt):
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 10,
                "temperature": 0.1,
                "return_full_text": False,
            },
            "options": {"wait_for_model": True}
        }
        try:
            response = requests.post(
                f"{self.api_url}{model_name}",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            if response.status_code == 200:
                return response.json()
            else:
                return {"error": f"API Error: {response.status_code} - {response.text}"}
        except Exception as e:
            return {"error": str(e)}

    def evaluate(self, model_name, questions, correct_answers, progress_bar):
        results = []
        total_questions = len(questions)

        for i, (question, correct_answer) in enumerate(zip(questions, correct_answers)):
            prompt = f"""{question}

Answer with the letter of the correct option (A, B, C, or D).

Answer:"""
            
            response = self.query_model(model_name, prompt)
            
            predicted_answer = "ERROR"
            raw_response = str(response)

            if isinstance(response, list) and 'generated_text' in response[0]:
                generated_text = response[0]['generated_text'].strip()
                raw_response = generated_text
                # A, B, C, D ì¤‘ í•˜ë‚˜ë¥¼ ì¶”ì¶œ
                match = re.search(r'\b([A-D])\b', generated_text.upper())
                if match:
                    predicted_answer = match.group(1)

            is_correct = predicted_answer == correct_answer
            results.append({
                'question': question,
                'correct_answer': correct_answer,
                'predicted_answer': predicted_answer,
                'is_correct': is_correct,
                'raw_response': raw_response
            })
            
            progress_bar.progress((i + 1) / total_questions)
            time.sleep(1) # API ìš”ì²­ ì œí•œì„ í”¼í•˜ê¸° ìœ„í•¨

        return results

# --- ë©”ì¸ ì•± ---

# í—¤ë”
st.markdown('<div class="main-header"><h1>ğŸ¥ MedLLM Simple Evaluator</h1></div>', unsafe_allow_html=True)

# --- ì…ë ¥ì„ ìœ„í•œ ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # 1. API í‚¤
    api_key = st.text_input("HuggingFace API Key", type="password", help="HuggingFace API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # 2. ëª¨ë¸ ì„ íƒ
    model_id = st.text_input("HuggingFace Model ID", "google/gemma-2b-it", help="ì˜ˆ: 'microsoft/BioGPT', 'google/gemma-2b-it'")

    # 3. ë°ì´í„°ì…‹ ì—…ë¡œë“œ
    st.subheader("ğŸ“Š ë°ì´í„°ì…‹")
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['csv'],
        help="CSV íŒŒì¼ì€ 'question'ê³¼ 'answer' ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
    )
    
    # ìƒ˜í”Œ CSV ë‹¤ìš´ë¡œë“œ
    simplified_sample = '''question,answer
"25ì„¸ ì—¬ì„±ì´ ì‹¬í•œ ë³µí†µìœ¼ë¡œ ì‘ê¸‰ì‹¤ì— ë‚´ì›í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì›”ê²½ì€ 6ì£¼ ì „ì´ì—ˆê³ , ì†Œë³€ ì„ì‹  ê²€ì‚¬ ê²°ê³¼ëŠ” ì–‘ì„±ì…ë‹ˆë‹¤. í˜ˆì••ì€ 90/60 mmHg, ë§¥ë°•ì€ ë¶„ë‹¹ 110íšŒì…ë‹ˆë‹¤. ê²€ì‚¬ ê²°ê³¼ ì¢Œí•˜ë³µë¶€ì— ì••í†µì´ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì§„ë‹¨ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\n\nA. ìê¶ì™¸ ì„ì‹ \nB. ë§¹ì¥ì—¼\nC. ë‚œì†Œ ë‚­ì¢… íŒŒì—´\nD. ê³¨ë°˜ ì—¼ì¦ì„± ì§ˆí™˜","A"
"45ì„¸ ë‚¨ì„±ì´ ìš´ë™ í›„ ì‹¬í•œ í‰í†µì„ í˜¸ì†Œí•©ë‹ˆë‹¤. í†µì¦ì€ ì™¼ìª½ ì–´ê¹¨ì™€ íŒ”ë¡œ ë°©ì‚¬ë˜ë©°, ì‹ì€ë•€ì„ í˜ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ì‹¬ì „ë„ìƒ V2-V4 ìœ ë„ì—ì„œ ST ë¶„ì ˆ ìƒìŠ¹ì´ ê´€ì°°ë©ë‹ˆë‹¤. ê°€ì¥ ì ì ˆí•œ ì´ˆê¸° ì¹˜ë£ŒëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?\n\nA. ì•„ìŠ¤í”¼ë¦°\nB. ì„¤í•˜ ë‹ˆíŠ¸ë¡œê¸€ë¦¬ì„¸ë¦°\nC. ì‚°ì†Œ\nD. ì¦‰ê°ì ì¸ ì‹¬ì¥ ë„ê´€ìˆ ","D"
'''
    st.download_button(
        label="ğŸ“¥ ìƒ˜í”Œ CSV ë‹¤ìš´ë¡œë“œ",
        data=simplified_sample,
        file_name="medical_qa_sample.csv",
        mime="text/csv"
    )

# --- í‰ê°€ ë¡œì§ ---
if st.button("ğŸš€ í‰ê°€ ì‹œì‘"):
    # ì…ë ¥ ê°’ ê²€ì¦
    if not api_key:
        st.error("âŒ HuggingFace API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not model_id:
        st.error("âŒ ëª¨ë¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif uploaded_file is None:
        st.error("âŒ ë°ì´í„°ì…‹ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        try:
            df = pd.read_csv(uploaded_file)
            if 'question' not in df.columns or 'answer' not in df.columns:
                st.error("âŒ CSV íŒŒì¼ì— 'question'ê³¼ 'answer' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                st.info(f"âœ… {len(df)}ê°œì˜ ì§ˆë¬¸ìœ¼ë¡œ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ.")
                st.info(f"ğŸ¤– ëª¨ë¸ í‰ê°€ ì¤‘: {model_id}")

                evaluator = MedicalQA(api_key)
                
                # ë°ì´í„° ì¤€ë¹„
                questions = df['question'].tolist()
                correct_answers = df['answer'].tolist()

                # í‰ê°€ ì‹¤í–‰
                progress_bar = st.progress(0)
                evaluation_results = evaluator.evaluate(model_id, questions, correct_answers, progress_bar)
                progress_bar.progress(1.0)
                st.success("ğŸ‰ í‰ê°€ ì™„ë£Œ!")

                # --- ê²°ê³¼ í‘œì‹œ ---
                correct_count = sum(1 for r in evaluation_results if r['is_correct'])
                total_count = len(evaluation_results)
                accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0

                st.metric("ğŸ† ìµœì¢… ì •í™•ë„", f"{accuracy:.2f}%", f"{correct_count} / {total_count} ì •ë‹µ")

                # ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¥ ê°€ëŠ¥í•œ í˜•íƒœë¡œ í‘œì‹œ
                with st.expander("ğŸ“„ ìƒì„¸ ê²°ê³¼ ë³´ê¸°"):
                    results_df = pd.DataFrame(evaluation_results)
                    st.dataframe(results_df)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ ì™„ë£Œí•œ í›„ 'í‰ê°€ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
